

Tokenization - processing of converting text into 'tokens'
Tokens - words or entities present in text
Text Object - a sentence, phrase, or word 


2. Text Preprocessing

